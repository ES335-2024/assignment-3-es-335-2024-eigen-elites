{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import torch\n",
    "import classes\n",
    "\n",
    "\n",
    "def find_model_path(model_type, e, b, h, h2 = 0):\n",
    "    if model_type==0:\n",
    "        return f\"/Users/nimitt/Documents/ML/ML-ES335/assignment3/model_states/model_{b}_{e}_{h}.pt\"\n",
    "    elif model_type==1:\n",
    "        return f\"/Users/nimitt/Documents/ML/ML-ES335/assignment3/model_states/model_{b}_{e}_{h}_{h2}.pt\"\n",
    "    else :\n",
    "        return \"/Users/nimitt/Documents/ML/ML-ES335/assignment3/model_states/model2.pt\"\n",
    "    \n",
    "\n",
    "def plot(model_type, emb_size, block_size):\n",
    "    st.title('Text Generation')\n",
    "\n",
    "    block_size_dict = {10:10,15:15,20:20,25:25}\n",
    "    embedding_size_dict = {4:4,6:6,8:8,10:10,12:12}\n",
    "    model_types = {\"MLP; layers : 2\":0, \"MLP; layers : 3\":1}\n",
    "\n",
    "    stored_X_tensors = torch.load(\"/Users/nimitt/Documents/ML/ML-ES335/assignment3/model_states/10.pt\")\n",
    "    stoi,itos =  stored_X_tensors['stoi'], stored_X_tensors['itos'] \n",
    "\n",
    "    model_type = model_types[st.selectbox(\"Model Type\",list(model_types.keys()))]\n",
    "    block_size = st.selectbox(\"Context Length\", list(block_size_dict.keys()))\n",
    "    embedding_size = st.selectbox(\"Embedding Size\", list(embedding_size_dict.keys()))\n",
    "    generate_text_len = st.slider('Lenght of generated text', 0, 100, 50, step=1)\n",
    "\n",
    "    st.write('Enter some text and click on Predict button')\n",
    "    input_text = st.text_area(\"Enter text...\")\n",
    "    input_text.lower()\n",
    "\n",
    "    hidden_size = 100\n",
    "    hidden_size_2 = 50\n",
    "\n",
    "    if model_type == 0:\n",
    "        model = classes.NextChar(block_size,len(stoi),embedding_size,hidden_size)\n",
    "    elif model_type == 1:\n",
    "        model = classes.NextCharDense(block_size,len(stoi),embedding_size,hidden_size,hidden_size_2)\n",
    "    else:\n",
    "        model = classes.NextChar(block_size,len(stoi),embedding_size,hidden_size)\n",
    "\n",
    "    model_path = find_model_path(model_type, embedding_size, block_size, hidden_size,hidden_size_2)\n",
    "    model = torch.compile(model)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "    classes.load_check_points(model,opt,model_path)\n",
    "\n",
    "    if st.button(\"Predict\"):\n",
    "        if input_text:\n",
    "            # Make predictions\n",
    "            seed = 100\n",
    "            text = classes.generate_text(seed, model, input_text, itos, stoi, block_size, generate_text_len)\n",
    "            text = text.replace('~','\\n')\n",
    "            st.write(f'{text}')\n",
    "        else:\n",
    "            st.write(\"Please enter some text to predict.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
